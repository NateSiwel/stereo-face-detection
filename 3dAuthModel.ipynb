{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from server import server, app, decode_img, list_to_numpy\n",
    "from serverClass import ServerClass\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_data.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = ServerClass()\n",
    "\n",
    "imgsL = []\n",
    "imgsR = []\n",
    "cam = list_to_numpy(data[0]['cam'])\n",
    "\n",
    "for obj in data:\n",
    "  imgL = obj['imgL']\n",
    "  imgR = obj['imgR'] \n",
    "  #cam = obj['cam']\n",
    "\n",
    "  imgL = decode_img(imgL)\n",
    "  imgR = decode_img(imgR)\n",
    "\n",
    "  imgsL.append(imgL)\n",
    "  imgsR.append(imgR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgsL_rect, imgsR_rect = [], []\n",
    "for imgL, imgR in zip(imgsL, imgsR):\n",
    "  imgL_rect, imgR_rect = server.rectify_frames(imgL, imgR, cam)\n",
    "  imgsL_rect.append(imgL_rect)\n",
    "  imgsR_rect.append(imgR_rect)\n",
    "\n",
    "#imgL_rect, imgR_rect = server.rectify_frames(imgL, imgR, cam)\n",
    "\n",
    "rectsL_list=[]\n",
    "for imgL_rect in imgsL_rect:\n",
    "  rectsL_list.append(face_recognition.face_locations(imgL_rect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "disparity_maps = []\n",
    "for imgL_rect, imgR_rect in zip(imgsL_rect, imgsR_rect):\n",
    "    #for top, right, bottom, left in rects:\n",
    "        #cv2.rectangle(imgL_rect, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "    disparity_map = server.get_disparity(\n",
    "        img1_rectified=imgL_rect, \n",
    "        img2_rectified=imgR_rect, \n",
    "        min_disp=-100, \n",
    "        max_disp=100, \n",
    "        block_size=1, \n",
    "        uniquenessRatio=0, \n",
    "        speckleWindowSize=0, \n",
    "        speckleRange=1, \n",
    "        disp12MaxDiff=0\n",
    "    )\n",
    "    disparity_maps.append(disparity_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor testing get_disparity parameters \\n\\n\\nindex = 25\\ntest_map = server.get_disparity(\\n        img1_rectified=imgsL_rect[index], \\n        img2_rectified=imgsR_rect[index], \\n        min_disp=-100, \\n        max_disp=100, \\n        block_size=1, \\n        uniquenessRatio=0, \\n        speckleWindowSize=0, \\n        speckleRange=1, \\n        disp12MaxDiff=0\\n    )\\n\\nfor disparity_map in disparity_maps:\\n    plt.imshow(disparity_map, cmap='gray')\\n    plt.title('Disparity Map')\\n    plt.colorbar()\\n    plt.show()\\n\\nplt.imshow(disparity_map, cmap='gray')\\nplt.title('Disparity Map')\\nplt.colorbar()\\nplt.show()\\n\\ncv2.imshow('img1', imgL)\\ncv2.waitKey(0)\\ncv2.destroyAllWindows()\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for testing get_disparity parameters \n",
    "\n",
    "\n",
    "index = 25\n",
    "test_map = server.get_disparity(\n",
    "        img1_rectified=imgsL_rect[index], \n",
    "        img2_rectified=imgsR_rect[index], \n",
    "        min_disp=-100, \n",
    "        max_disp=100, \n",
    "        block_size=1, \n",
    "        uniquenessRatio=0, \n",
    "        speckleWindowSize=0, \n",
    "        speckleRange=1, \n",
    "        disp12MaxDiff=0\n",
    "    )\n",
    "\n",
    "for disparity_map in disparity_maps:\n",
    "    plt.imshow(disparity_map, cmap='gray')\n",
    "    plt.title('Disparity Map')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "plt.imshow(disparity_map, cmap='gray')\n",
    "plt.title('Disparity Map')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "cv2.imshow('img1', imgL)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "40\n",
      "0\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "29\n",
      "31\n",
      "32\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "disparity_faces = []\n",
    "padding_percentage = 0.20\n",
    "target_size = (224,224)\n",
    "\n",
    "print(len(rectsL_list[20]))\n",
    "print(len(disparity_maps))\n",
    "\n",
    "for i, rectsL in enumerate(rectsL_list):\n",
    "    height, width = disparity_maps[i].shape[:2]  # Get the dimensions of the disparity map\n",
    "    face_region=None\n",
    "\n",
    "    for x, (top, right, bottom, left) in enumerate(rectsL):\n",
    "\n",
    "        # Calculate dynamic padding based on the size of the face\n",
    "        pad_w = int((right - left) * padding_percentage)\n",
    "        pad_h = int((bottom - top) * padding_percentage)\n",
    "\n",
    "\n",
    "        \n",
    "        # Apply padding and ensure indices are within the image bounds\n",
    "        padded_top = max(top - pad_h, 0)\n",
    "        padded_bottom = min(bottom + pad_h, height)\n",
    "        padded_left = max(left - pad_w, 0)\n",
    "        padded_right = min(right + pad_w, width)\n",
    "        \n",
    "        # Extract the face region with padding\n",
    "        face_region = disparity_maps[i][padded_top:padded_bottom, padded_left:padded_right]\n",
    "        face_normal = imgsL_rect[i][padded_top:padded_bottom, padded_left:padded_right]\n",
    "\n",
    "        face_region_resized = cv2.resize(face_region, target_size, interpolation=cv2.INTER_AREA)\n",
    "        face_normal_resized = cv2.resize(face_normal, target_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        if i == 20:\n",
    "            cv2.imshow('face', imgsL_rect[i])\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "        \"\"\"\n",
    "\n",
    "        print(i)\n",
    "\n",
    "    disparity_faces.append(face_region_resized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor i, (top, right, bottom, left) in enumerate(rectsL):\\n    # Draw rectangle on the disparity map\\n    cv2.rectangle(disparity_map, (left, top), (right, bottom), (255, 0, 0), 2)\\n\\ncv2.imshow('Disparity Map with Face Regions', disparity_map)\\ncv2.waitKey(0)  # Wait for a key press to close\\ncv2.destroyAllWindows()\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for i, (top, right, bottom, left) in enumerate(rectsL):\n",
    "    # Draw rectangle on the disparity map\n",
    "    cv2.rectangle(disparity_map, (left, top), (right, bottom), (255, 0, 0), 2)\n",
    "\n",
    "cv2.imshow('Disparity Map with Face Regions', disparity_map)\n",
    "cv2.waitKey(0)  # Wait for a key press to close\n",
    "cv2.destroyAllWindows()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor face in disparity_faces:\\n  plt.figure(figsize=(10, 7))\\n  plt.imshow(face, cmap='gray')\\n  plt.title('Disparity Map')\\n  plt.colorbar()  # Adds a colorbar to interpret the values\\n  plt.show()\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the disparity map using matplotlib\n",
    "\n",
    "\"\"\"\n",
    "for face in disparity_faces:\n",
    "  plt.figure(figsize=(10, 7))\n",
    "  plt.imshow(face, cmap='gray')\n",
    "  plt.title('Disparity Map')\n",
    "  plt.colorbar()  # Adds a colorbar to interpret the values\n",
    "  plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 21\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(disparity_maps[index], cmap='gray')\n",
    "plt.title('Disparity Map')\n",
    "plt.colorbar()  # Adds a colorbar to interpret the values\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for i, face in enumerate(disparity_faces):\n",
    "  if face is not None:\n",
    "    X_train.append(face)\n",
    "\n",
    "    #1 for valid face, 0 for invalid face\n",
    "    if i > 21:\n",
    "      y_train.append(0)\n",
    "    else:\n",
    "      y_train.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 128)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.act1(self.conv1(x)))\n",
    "        x = self.pool2(self.act2(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) \n",
    "        x = self.act3(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)\n",
    "print(X_train_tensor.shape)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 55.80411946773529\n",
      "Epoch 2, Loss: 92.74967041015626\n",
      "Epoch 3, Loss: 16.947527122497558\n",
      "Epoch 4, Loss: 0.0\n",
      "Epoch 5, Loss: 2.0714488983154298\n",
      "Epoch 6, Loss: 0.0\n",
      "Epoch 7, Loss: 0.0\n",
      "Epoch 8, Loss: 0.0\n",
      "Epoch 9, Loss: 0.0\n",
      "Epoch 10, Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 224, 224])\n",
      "Predicted class: 0\n",
      "Probabilities: tensor([[1., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# set model to eval mode\n",
    "model.eval()\n",
    "\n",
    "#prep input image\n",
    "test_image = torch.tensor(X_train[22], dtype=torch.float32).unsqueeze(0)\n",
    "test_image = test_image.unsqueeze(1)\n",
    "test_image = test_image.to(device) \n",
    "print(test_image.shape)\n",
    "\n",
    "with torch.no_grad(): \n",
    "    output = model(test_image)\n",
    "\n",
    "probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "predicted_class = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "print(f\"Predicted class: {predicted_class.item()}\")\n",
    "print(f\"Probabilities: {probabilities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_state_dict.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
